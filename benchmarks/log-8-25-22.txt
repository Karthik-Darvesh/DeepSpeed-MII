benchmarking model 0
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 0: skt/kogpt2-base-v2, gpt2, text-generation, 128.45 M with enable_deepspeed=True
[2022-08-26 00:41:38,462] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: True*************
[2022-08-26 00:41:38,464] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'skt/kogpt2-base-v2', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/skt/kogpt2-base-v2', '--port', '50050', '--ds-optimize', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:41:40,799] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:41:40,799] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model skt/kogpt2-base-v2 --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/skt/kogpt2-base-v2 --port 50050 --ds-optimize --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:41:42,328] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:41:42,328] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:41:42,328] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:41:42,328] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:41:42,328] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:41:42,328] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:41:42,328] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:41:42,328] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:41:42,328] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:41:42,328] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:41:42,328] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:41:42,328] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:41:43,480] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:41:44.508818: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:41:48,485] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[2022-08-26 00:41:53,080] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.2+2a644488, git-hash=2a644488, git-branch=master
[2022-08-26 00:41:53,080] [INFO] [logging.py:68:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[2022-08-26 00:41:53,486] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
Using /home/amawa/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/amawa/.cache/torch_extensions/py38_cu113/transformer_inference/build.ninja...
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.48859405517578125 seconds
[2022-08-26 00:41:54,548] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 768, 'intermediate_size': 3072, 'heads': 12, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False}
About to start server
Started
[2022-08-26 00:41:58,490] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:42:03,495] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:42:03,495] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
mean time_taken: 0.05646039310254549
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 0: skt/kogpt2-base-v2, gpt2, text-generation, 128.45 M with enable_deepspeed=False
[2022-08-26 00:42:14,065] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: False*************
[2022-08-26 00:42:14,069] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'skt/kogpt2-base-v2', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/skt/kogpt2-base-v2', '--port', '50050', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:42:16,210] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:42:16,211] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model skt/kogpt2-base-v2 --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/skt/kogpt2-base-v2 --port 50050 --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:42:17,681] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:42:17,681] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:42:17,681] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:42:17,681] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:42:17,681] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:42:17,681] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:42:17,681] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:42:17,681] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:42:17,681] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:42:17,681] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:42:17,681] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:42:17,681] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:42:19,084] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:42:19.913948: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:42:24,085] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
About to start server
Started
[2022-08-26 00:42:29,090] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:42:34,095] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:42:34,095] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
mean time_taken: 0.11389926860207006
False, 0.11389926860207006, 2.01733042126012

Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
benchmarking model 1
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 1: distilgpt2, gpt2, text-generation, 88.08 M with enable_deepspeed=True
[2022-08-26 00:42:50,790] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: True*************
[2022-08-26 00:42:50,792] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'distilgpt2', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/distilgpt2', '--port', '50050', '--ds-optimize', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:42:53,045] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:42:53,045] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model distilgpt2 --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/distilgpt2 --port 50050 --ds-optimize --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:42:54,641] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:42:54,641] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:42:54,641] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:42:54,641] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:42:54,641] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:42:54,641] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:42:54,641] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:42:54,641] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:42:54,641] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:42:54,641] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:42:54,641] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:42:54,641] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:42:55,809] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:42:56.821484: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:43:00,814] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:43:04,883] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.2+2a644488, git-hash=2a644488, git-branch=master
[2022-08-26 00:43:04,884] [INFO] [logging.py:68:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[2022-08-26 00:43:05,818] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
Using /home/amawa/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/amawa/.cache/torch_extensions/py38_cu113/transformer_inference/build.ninja...
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.5201969146728516 seconds
[2022-08-26 00:43:06,379] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 768, 'intermediate_size': 3072, 'heads': 12, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False}
About to start server
Started
[2022-08-26 00:43:10,823] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:43:15,828] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:43:15,828] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.050454716933401006
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 1: distilgpt2, gpt2, text-generation, 88.08 M with enable_deepspeed=False
[2022-08-26 00:43:25,875] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: False*************
[2022-08-26 00:43:25,879] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'distilgpt2', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/distilgpt2', '--port', '50050', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:43:28,155] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:43:28,156] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model distilgpt2 --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/distilgpt2 --port 50050 --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:43:29,694] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:43:29,694] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:43:29,694] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:43:29,694] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:43:29,695] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:43:29,695] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:43:29,695] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:43:29,695] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:43:29,695] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:43:29,695] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:43:29,695] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:43:29,695] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:43:30,893] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:43:31.992399: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:43:35,897] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
About to start server
Started
[2022-08-26 00:43:40,902] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:43:45,907] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:43:45,907] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.09222126007080078
False, 0.09222126007080078, 1.827802546044022

Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
benchmarking model 2
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 2: sshleifer/tiny-gpt2, gpt2, text-generation, 629.15 K with enable_deepspeed=True
[2022-08-26 00:44:02,411] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: True*************
[2022-08-26 00:44:02,415] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'sshleifer/tiny-gpt2', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/sshleifer/tiny-gpt2', '--port', '50050', '--ds-optimize', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:44:04,754] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:44:04,754] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model sshleifer/tiny-gpt2 --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/sshleifer/tiny-gpt2 --port 50050 --ds-optimize --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:44:06,256] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:44:06,256] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:44:06,256] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:44:06,256] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:44:06,256] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:44:06,256] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:44:06,256] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:44:06,256] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:44:06,256] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:44:06,256] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:44:06,256] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:44:06,256] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:44:07,430] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:44:08.440608: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:44:12,435] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:44:16,396] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.2+2a644488, git-hash=2a644488, git-branch=master
[2022-08-26 00:44:16,396] [INFO] [logging.py:68:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
Using /home/amawa/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
[2022-08-26 00:44:17,439] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/amawa/.cache/torch_extensions/py38_cu113/transformer_inference/build.ninja...
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.4669175148010254 seconds
[2022-08-26 00:44:17,777] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 2, 'intermediate_size': 8, 'heads': 2, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False}
About to start server
Started
[2022-08-26 00:44:22,444] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:44:27,449] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:44:27,449] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
WARNING: Logging before flag parsing goes to stderr.
E0826 00:44:28.189552 140501832472320 _server.py:453] Exception calling application: CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "/home/amawa/.local/lib/python3.8/site-packages/grpc/_server.py", line 443, in _call_behavior
    response_or_iterator = behavior(argument, context)
  File "/opt/conda/lib/python3.8/site-packages/mii/grpc_related/modelresponse_server.py", line 32, in GeneratorReply
    response = self.inference_pipeline(request.request, **query_kwargs)
  File "/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/text_generation.py", line 176, in __call__
    return super().__call__(text_inputs, **kwargs)
  File "/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py", line 1043, in __call__
    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)
  File "/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py", line 1050, in run_single
    model_outputs = self.forward(model_inputs, **forward_params)
  File "/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py", line 959, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
  File "/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/text_generation.py", line 215, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, **generate_kwargs)  # BS x SL
  File "/home/amawa/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/amawa/.local/lib/python3.8/site-packages/transformers/generation_utils.py", line 1320, in generate
    return self.sample(
  File "/home/amawa/.local/lib/python3.8/site-packages/transformers/generation_utils.py", line 1938, in sample
    outputs = self(
  File "/home/amawa/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1148, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/amawa/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1048, in forward
    transformer_outputs = self.transformer(
  File "/home/amawa/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/amawa/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 917, in forward
    hidden_states = self.ln_f(hidden_states)
  File "/home/amawa/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/amawa/.local/lib/python3.8/site-packages/torch/nn/modules/normalization.py", line 189, in forward
    return F.layer_norm(
  File "/home/amawa/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 2503, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "bench_models.py", line 203, in <module>
    result = generator.query({'query': input}, do_sample=True, min_length=25, max_length=25)
  File "/opt/conda/lib/python3.8/site-packages/mii/server_client.py", line 318, in query
    response = self.asyncio_loop.run_until_complete(
  File "/opt/conda/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/conda/lib/python3.8/site-packages/mii/server_client.py", line 226, in _query_in_tensor_parallel
    await responses[0]
  File "/opt/conda/lib/python3.8/site-packages/mii/server_client.py", line 233, in _request_async_response
    response = await self.stubs[stub_id].GeneratorReply(
  File "/home/amawa/.local/lib/python3.8/site-packages/grpc/aio/_call.py", line 290, in __await__
    raise _create_rpc_error(self._cython_call._initial_metadata,
grpc.aio._call.AioRpcError: <AioRpcError of RPC that terminated with:
	status = StatusCode.UNKNOWN
	details = "Exception calling application: CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1."
	debug_error_string = "{"created":"@1661456668.203492374","description":"Error received from peer ipv4:127.0.0.1:50050","file":"src/core/lib/surface/call.cc","file_line":966,"grpc_message":"Exception calling application: CUDA error: invalid configuration argument\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.","grpc_status":2}"
>
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 2: sshleifer/tiny-gpt2, gpt2, text-generation, 629.15 K with enable_deepspeed=False
[2022-08-26 00:44:36,176] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: False*************
[2022-08-26 00:44:36,179] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'sshleifer/tiny-gpt2', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/sshleifer/tiny-gpt2', '--port', '50050', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:44:38,320] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:44:38,320] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model sshleifer/tiny-gpt2 --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/sshleifer/tiny-gpt2 --port 50050 --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:44:39,849] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:44:39,849] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:44:39,849] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:44:39,849] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:44:39,849] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:44:39,849] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:44:39,849] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:44:39,849] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:44:39,849] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:44:39,849] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:44:39,849] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:44:39,849] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:44:41,192] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:44:42.026576: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:44:46,197] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
About to start server
Started
[2022-08-26 00:44:51,202] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:44:56,206] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:44:56,207] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.04327864395944696
False, 0.04327864395944696, 0.02367796458819716

Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
benchmarking model 3
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 3: sberbank-ai/rugpt3large_based_on_gpt2, gpt2, text-generation, 786.52 M with enable_deepspeed=True
[2022-08-26 00:45:12,412] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: True*************
[2022-08-26 00:45:12,414] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'sberbank-ai/rugpt3large_based_on_gpt2', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/sberbank-ai/rugpt3large_based_on_gpt2', '--port', '50050', '--ds-optimize', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:45:14,874] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:45:14,875] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model sberbank-ai/rugpt3large_based_on_gpt2 --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/sberbank-ai/rugpt3large_based_on_gpt2 --port 50050 --ds-optimize --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:45:17,429] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:45:20,886] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:45:20,887] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:45:20,887] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:45:20,887] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:45:20,887] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:45:20,887] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:45:20,887] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:45:20,887] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:45:20,887] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:45:20,887] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:45:20,887] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:45:20,887] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:45:22,434] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:45:24.263941: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:45:27,438] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:45:32,443] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:45:37,445] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:45:42,450] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:45:47,455] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:45:52,459] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:45:57,464] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:46:02,468] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:46:07,473] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:46:12,477] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:46:17,482] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:46:22,485] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[2022-08-26 00:46:26,911] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.2+2a644488, git-hash=2a644488, git-branch=master
[2022-08-26 00:46:26,911] [INFO] [logging.py:68:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[2022-08-26 00:46:27,487] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
Using /home/amawa/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/amawa/.cache/torch_extensions/py38_cu113/transformer_inference/build.ninja...
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.46699047088623047 seconds
[2022-08-26 00:46:28,673] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1536, 'intermediate_size': 6144, 'heads': 16, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False}
About to start server
Started
[2022-08-26 00:46:32,491] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:46:37,496] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:46:37,496] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.11495846196224815
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 3: sberbank-ai/rugpt3large_based_on_gpt2, gpt2, text-generation, 786.52 M with enable_deepspeed=False
[2022-08-26 00:46:49,649] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: False*************
[2022-08-26 00:46:49,651] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'sberbank-ai/rugpt3large_based_on_gpt2', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/sberbank-ai/rugpt3large_based_on_gpt2', '--port', '50050', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:46:52,150] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:46:52,150] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model sberbank-ai/rugpt3large_based_on_gpt2 --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/sberbank-ai/rugpt3large_based_on_gpt2 --port 50050 --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:46:53,662] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:46:53,662] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:46:53,662] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:46:53,662] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:46:53,662] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:46:53,662] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:46:53,662] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:46:53,662] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:46:53,662] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:46:53,662] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:46:53,662] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:46:53,662] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:46:54,667] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:46:55.836973: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:46:59,671] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:47:04,673] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:47:09,678] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
About to start server
Started
[2022-08-26 00:47:14,683] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:47:19,688] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:47:19,688] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.24924551813225998
False, 0.24924551813225998, 2.168135462825791

Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
benchmarking model 4
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 4: mrm8488/distilgpt2-finetuned-wsb-tweets, gpt2, text-generation, 83.62 M with enable_deepspeed=True
[2022-08-26 00:47:39,475] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: True*************
[2022-08-26 00:47:39,477] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'mrm8488/distilgpt2-finetuned-wsb-tweets', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/mrm8488/distilgpt2-finetuned-wsb-tweets', '--port', '50050', '--ds-optimize', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:47:41,795] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:47:41,795] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model mrm8488/distilgpt2-finetuned-wsb-tweets --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/mrm8488/distilgpt2-finetuned-wsb-tweets --port 50050 --ds-optimize --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:47:43,440] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:47:43,441] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:47:43,441] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:47:43,441] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:47:43,441] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:47:43,441] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:47:43,441] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:47:43,441] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:47:43,441] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:47:43,441] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:47:43,441] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:47:43,441] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:47:44,491] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:47:46.292063: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:47:49,496] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:47:54,497] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:47:59,501] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:48:00,341] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.2+2a644488, git-hash=2a644488, git-branch=master
[2022-08-26 00:48:00,341] [INFO] [logging.py:68:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
Using /home/amawa/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/amawa/.cache/torch_extensions/py38_cu113/transformer_inference/build.ninja...
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.5167496204376221 seconds
[2022-08-26 00:48:01,801] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 768, 'intermediate_size': 3072, 'heads': 12, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False}
About to start server
Started
[2022-08-26 00:48:04,505] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:48:09,509] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:48:09,510] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.04986212128087094
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 4: mrm8488/distilgpt2-finetuned-wsb-tweets, gpt2, text-generation, 83.62 M with enable_deepspeed=False
[2022-08-26 00:48:19,953] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: False*************
[2022-08-26 00:48:19,955] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'mrm8488/distilgpt2-finetuned-wsb-tweets', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/mrm8488/distilgpt2-finetuned-wsb-tweets', '--port', '50050', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:48:22,155] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:48:22,156] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model mrm8488/distilgpt2-finetuned-wsb-tweets --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/mrm8488/distilgpt2-finetuned-wsb-tweets --port 50050 --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:48:23,692] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:48:23,692] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:48:23,692] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:48:23,692] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:48:23,692] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:48:23,692] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:48:23,692] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:48:23,692] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:48:23,692] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:48:23,692] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:48:23,692] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:48:23,692] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:48:24,972] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:48:25.872616: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:48:29,977] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
About to start server
Started
[2022-08-26 00:48:34,981] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:48:39,986] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:48:39,986] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.09294763364289936
False, 0.09294763364289936, 1.8640930480941593

Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
benchmarking model 5
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 5: gpt2-xl, gpt2, text-generation, 1.61 G with enable_deepspeed=True
[2022-08-26 00:48:55,836] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: True*************
[2022-08-26 00:48:55,838] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'gpt2-xl', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/gpt2-xl', '--port', '50050', '--ds-optimize', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:48:57,948] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:48:57,949] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model gpt2-xl --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/gpt2-xl --port 50050 --ds-optimize --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:48:59,475] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:48:59,475] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:48:59,475] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:48:59,475] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:48:59,475] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:48:59,475] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:48:59,475] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:48:59,475] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:48:59,475] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:48:59,475] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:48:59,475] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:48:59,475] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:49:00,854] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:49:01.769546: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:49:05,859] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:49:10,861] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:49:15,865] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:49:20,870] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:49:24,284] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.2+2a644488, git-hash=2a644488, git-branch=master
[2022-08-26 00:49:24,284] [INFO] [logging.py:68:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
Using /home/amawa/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/amawa/.cache/torch_extensions/py38_cu113/transformer_inference/build.ninja...
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[2022-08-26 00:49:25,873] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.6185488700866699 seconds
[2022-08-26 00:49:25,934] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1600, 'intermediate_size': 6400, 'heads': 25, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False}
About to start server
Started
[2022-08-26 00:49:30,877] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:49:35,881] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:49:35,882] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.25813811703732137
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 5: gpt2-xl, gpt2, text-generation, 1.61 G with enable_deepspeed=False
[2022-08-26 00:49:51,492] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: False*************
[2022-08-26 00:49:51,495] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'gpt2-xl', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/gpt2-xl', '--port', '50050', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:49:53,643] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:49:53,643] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model gpt2-xl --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/gpt2-xl --port 50050 --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:49:55,153] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:49:55,153] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:49:55,153] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:49:55,153] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:49:55,153] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:49:55,153] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:49:55,153] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:49:55,153] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:49:55,153] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:49:55,154] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:49:55,154] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:49:55,154] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:49:56,509] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:49:57.341277: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:50:01,514] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:50:06,519] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:50:11,523] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:50:16,525] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:50:21,528] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:50:26,532] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
About to start server
Started
[2022-08-26 00:50:31,537] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:50:36,541] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:50:36,542] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.5912741861845318
False, 0.5912741861845318, 2.2905342030485403

Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
benchmarking model 6
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 6: gpt2-medium, gpt2, text-generation, 381.18 M with enable_deepspeed=True
[2022-08-26 00:51:03,473] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: True*************
[2022-08-26 00:51:03,476] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'gpt2-medium', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/gpt2-medium', '--port', '50050', '--ds-optimize', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:51:05,705] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:51:05,706] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model gpt2-medium --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/gpt2-medium --port 50050 --ds-optimize --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:51:07,231] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:51:07,231] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:51:07,231] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:51:07,231] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:51:07,231] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:51:07,231] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:51:07,231] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:51:07,232] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:51:07,232] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:51:07,232] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:51:07,232] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:51:07,232] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:51:08,490] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:51:09.526137: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:51:13,493] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:51:18,497] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:51:23,502] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:51:28,505] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:51:33,510] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:51:38,515] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:51:42,357] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.2+2a644488, git-hash=2a644488, git-branch=master
[2022-08-26 00:51:42,357] [INFO] [logging.py:68:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
Using /home/amawa/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
[2022-08-26 00:51:43,517] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/amawa/.cache/torch_extensions/py38_cu113/transformer_inference/build.ninja...
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.4809231758117676 seconds
[2022-08-26 00:51:43,751] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1024, 'intermediate_size': 4096, 'heads': 16, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False}
About to start server
Started
[2022-08-26 00:51:48,521] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:51:53,526] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:51:53,526] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.14254114502354673
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 6: gpt2-medium, gpt2, text-generation, 381.18 M with enable_deepspeed=False
[2022-08-26 00:52:06,739] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: False*************
[2022-08-26 00:52:06,742] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'gpt2-medium', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/gpt2-medium', '--port', '50050', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:52:08,915] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:52:08,915] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model gpt2-medium --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/gpt2-medium --port 50050 --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:52:10,422] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:52:10,422] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:52:10,422] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:52:10,422] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:52:10,422] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:52:10,422] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:52:10,422] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:52:10,422] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:52:10,423] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:52:10,423] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:52:10,423] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:52:10,423] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:52:11,758] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:52:12.645999: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:52:16,763] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:52:21,768] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
About to start server
Started
[2022-08-26 00:52:26,772] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:52:31,777] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:52:31,777] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.31690980258740875
False, 0.31690980258740875, 2.2232864941211017

Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
benchmarking model 7
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 7: mrm8488/diltilgpt2-finetuned-bookcopus-10, gpt2, text-generation, 83.62 M with enable_deepspeed=True
[2022-08-26 00:52:52,031] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: True*************
[2022-08-26 00:52:52,033] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'mrm8488/diltilgpt2-finetuned-bookcopus-10', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/mrm8488/diltilgpt2-finetuned-bookcopus-10', '--port', '50050', '--ds-optimize', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:52:54,199] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:52:54,200] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model mrm8488/diltilgpt2-finetuned-bookcopus-10 --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/mrm8488/diltilgpt2-finetuned-bookcopus-10 --port 50050 --ds-optimize --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:52:55,820] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:52:55,820] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:52:55,820] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:52:55,820] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:52:55,820] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:52:55,820] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:52:55,820] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:52:55,820] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:52:55,820] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:52:55,820] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:52:55,820] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:52:55,821] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:52:57,049] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:52:57.982190: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:53:02,053] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:53:07,057] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:53:12,062] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:53:12,134] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.2+2a644488, git-hash=2a644488, git-branch=master
[2022-08-26 00:53:12,134] [INFO] [logging.py:68:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
Using /home/amawa/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/amawa/.cache/torch_extensions/py38_cu113/transformer_inference/build.ninja...
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.5144329071044922 seconds
[2022-08-26 00:53:13,848] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 768, 'intermediate_size': 3072, 'heads': 12, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False}
About to start server
Started
[2022-08-26 00:53:17,067] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:53:22,069] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:53:22,070] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.04968300618623432
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 7: mrm8488/diltilgpt2-finetuned-bookcopus-10, gpt2, text-generation, 83.62 M with enable_deepspeed=False
[2022-08-26 00:53:33,025] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: False*************
[2022-08-26 00:53:33,028] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'mrm8488/diltilgpt2-finetuned-bookcopus-10', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/mrm8488/diltilgpt2-finetuned-bookcopus-10', '--port', '50050', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:53:35,197] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:53:35,198] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model mrm8488/diltilgpt2-finetuned-bookcopus-10 --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/mrm8488/diltilgpt2-finetuned-bookcopus-10 --port 50050 --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:53:36,826] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:53:36,826] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:53:36,826] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:53:36,826] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:53:36,826] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:53:36,826] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:53:36,826] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:53:36,826] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:53:36,826] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:53:36,826] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:53:36,826] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:53:36,826] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:53:38,045] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:53:39.035014: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:53:43,050] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
About to start server
Started
[2022-08-26 00:53:48,055] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:53:53,057] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:53:53,058] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.09261623181794819
False, 0.09261623181794819, 1.8641430727999986

Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
benchmarking model 8
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 8: shibing624/code-autocomplete-distilgpt2-python, gpt2, text-generation, 83.62 M with enable_deepspeed=True
[2022-08-26 00:54:08,935] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: True*************
[2022-08-26 00:54:08,939] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'shibing624/code-autocomplete-distilgpt2-python', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/shibing624/code-autocomplete-distilgpt2-python', '--port', '50050', '--ds-optimize', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:54:11,185] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:54:11,185] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model shibing624/code-autocomplete-distilgpt2-python --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/shibing624/code-autocomplete-distilgpt2-python --port 50050 --ds-optimize --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:54:12,783] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:54:12,784] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:54:12,784] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:54:12,784] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:54:12,784] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:54:12,784] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:54:12,784] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:54:12,784] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:54:12,784] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:54:12,784] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:54:12,784] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:54:12,784] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:54:13,954] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:54:15.212720: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:54:18,959] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:54:23,961] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:54:28,150] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.2+2a644488, git-hash=2a644488, git-branch=master
[2022-08-26 00:54:28,150] [INFO] [logging.py:68:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[2022-08-26 00:54:28,966] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
Using /home/amawa/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/amawa/.cache/torch_extensions/py38_cu113/transformer_inference/build.ninja...
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.5012674331665039 seconds
[2022-08-26 00:54:29,594] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 768, 'intermediate_size': 3072, 'heads': 12, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False}
About to start server
Started
[2022-08-26 00:54:33,971] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:54:38,976] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:54:38,976] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.04989591397737202
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 8: shibing624/code-autocomplete-distilgpt2-python, gpt2, text-generation, 83.62 M with enable_deepspeed=False
[2022-08-26 00:54:50,703] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: False*************
[2022-08-26 00:54:50,705] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'shibing624/code-autocomplete-distilgpt2-python', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/shibing624/code-autocomplete-distilgpt2-python', '--port', '50050', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:54:52,915] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:54:52,915] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model shibing624/code-autocomplete-distilgpt2-python --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/shibing624/code-autocomplete-distilgpt2-python --port 50050 --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:54:54,435] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:54:54,435] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:54:54,435] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:54:54,435] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:54:54,435] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:54:54,435] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:54:54,435] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:54:54,436] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:54:54,436] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:54:54,436] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:54:54,436] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:54:54,436] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:54:55,717] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:54:56.576932: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:55:00,721] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
About to start server
Started
[2022-08-26 00:55:05,726] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:55:10,727] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:55:10,728] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.09270023044786956
False, 0.09270023044786956, 1.8578721794716389

Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
benchmarking model 9
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 9: geralt/MechDistilGPT2, gpt2, text-generation, 83.62 M with enable_deepspeed=True
[2022-08-26 00:55:29,131] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: True*************
[2022-08-26 00:55:29,133] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'geralt/MechDistilGPT2', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/geralt/MechDistilGPT2', '--port', '50050', '--ds-optimize', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:55:31,255] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:55:31,256] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model geralt/MechDistilGPT2 --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/geralt/MechDistilGPT2 --port 50050 --ds-optimize --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:55:32,758] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:55:32,758] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:55:32,758] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:55:32,758] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:55:32,758] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:55:32,758] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:55:32,758] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:55:32,758] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:55:32,758] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:55:32,758] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:55:32,758] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:55:32,758] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:55:34,149] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:55:34.974446: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:55:39,154] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:55:44,157] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:55:48,884] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.2+2a644488, git-hash=2a644488, git-branch=master
[2022-08-26 00:55:48,884] [INFO] [logging.py:68:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[2022-08-26 00:55:49,162] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
Using /home/amawa/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/amawa/.cache/torch_extensions/py38_cu113/transformer_inference/build.ninja...
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.5061805248260498 seconds
[2022-08-26 00:55:50,332] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 768, 'intermediate_size': 3072, 'heads': 12, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False}
About to start server
Started
[2022-08-26 00:55:54,167] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:55:59,172] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:55:59,172] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.049563859638414885
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 9: geralt/MechDistilGPT2, gpt2, text-generation, 83.62 M with enable_deepspeed=False
[2022-08-26 00:56:10,480] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: False*************
[2022-08-26 00:56:10,483] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'geralt/MechDistilGPT2', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/geralt/MechDistilGPT2', '--port', '50050', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:56:12,657] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:56:12,658] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model geralt/MechDistilGPT2 --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/geralt/MechDistilGPT2 --port 50050 --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:56:14,185] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:56:14,186] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:56:14,186] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:56:14,186] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:56:14,186] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:56:14,186] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:56:14,186] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:56:14,186] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:56:14,186] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:56:14,186] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:56:14,186] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:56:14,186] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:56:15,499] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:56:16.364977: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:56:20,501] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
About to start server
Started
[2022-08-26 00:56:25,506] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:56:30,511] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:56:30,511] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.08918453517713044
False, 0.08918453517713044, 1.7993864042825112

Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
benchmarking model 10
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 10: gpt2, gpt2, text-generation, 137.1 M with enable_deepspeed=True
[2022-08-26 00:56:46,283] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: True*************
[2022-08-26 00:56:46,286] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'gpt2', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/gpt2', '--port', '50050', '--ds-optimize', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:56:48,435] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:56:48,436] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model gpt2 --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/gpt2 --port 50050 --ds-optimize --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:56:49,959] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:56:49,959] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:56:49,959] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:56:49,959] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:56:49,959] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:56:49,959] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:56:49,959] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:56:49,959] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:56:49,959] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:56:49,959] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:56:49,959] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:56:49,959] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:56:51,302] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:56:52.215353: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:56:56,306] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:57:01,311] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:57:06,316] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:57:09,163] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.2+2a644488, git-hash=2a644488, git-branch=master
[2022-08-26 00:57:09,163] [INFO] [logging.py:68:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
Using /home/amawa/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/amawa/.cache/torch_extensions/py38_cu113/transformer_inference/build.ninja...
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.4787788391113281 seconds
[2022-08-26 00:57:10,545] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 768, 'intermediate_size': 3072, 'heads': 12, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False}
About to start server
Started
[2022-08-26 00:57:11,320] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:57:16,325] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:57:16,325] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.0777932091763145
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 10: gpt2, gpt2, text-generation, 137.1 M with enable_deepspeed=False
[2022-08-26 00:57:27,685] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: False*************
[2022-08-26 00:57:27,687] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'gpt2', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/gpt2', '--port', '50050', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:57:29,899] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:57:29,900] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model gpt2 --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/gpt2 --port 50050 --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:57:31,456] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:57:31,456] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:57:31,456] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:57:31,456] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:57:31,456] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:57:31,456] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:57:31,456] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:57:31,457] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:57:31,457] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:57:31,457] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:57:31,457] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:57:31,457] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:57:32,703] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:57:33.660972: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:57:37,708] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:57:42,712] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
About to start server
Started
[2022-08-26 00:57:47,717] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:57:52,725] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:57:52,725] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.1593498430754009
False, 0.1593498430754009, 2.048377291059458

Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
benchmarking model 11
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 11: gpt2-large, gpt2, text-generation, 810.68 M with enable_deepspeed=True
[2022-08-26 00:58:10,979] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: True*************
[2022-08-26 00:58:10,982] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'gpt2-large', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/gpt2-large', '--port', '50050', '--ds-optimize', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:58:13,152] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:58:13,152] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model gpt2-large --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/gpt2-large --port 50050 --ds-optimize --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:58:14,756] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:58:14,757] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:58:14,757] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:58:14,757] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:58:14,757] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:58:14,757] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:58:14,757] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:58:14,757] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:58:14,757] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:58:14,757] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:58:14,757] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:58:14,757] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:58:15,997] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:58:16.958981: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:58:21,001] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:58:26,006] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:58:31,009] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:58:36,014] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:58:41,019] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:58:46,023] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:58:51,028] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:58:56,033] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:59:01,037] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:59:06,042] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:59:11,045] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:59:16,050] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:59:18,709] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.2+2a644488, git-hash=2a644488, git-branch=master
[2022-08-26 00:59:18,709] [INFO] [logging.py:68:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
Using /home/amawa/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/amawa/.cache/torch_extensions/py38_cu113/transformer_inference/build.ninja...
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.4600827693939209 seconds
[2022-08-26 00:59:20,613] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1280, 'intermediate_size': 5120, 'heads': 20, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False}
About to start server
Started
[2022-08-26 00:59:21,055] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:59:26,057] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:59:26,058] [INFO] [server_client.py:117:_wait_until_server_is_live] server has started on 50050
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/home/amawa/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1012: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
mean time_taken: 0.19590263617666145
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Exception ignored in: 'grpc._cython.cygrpc.AioChannel.__dealloc__'
Traceback (most recent call last):
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 110, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 114, in grpc._cython.cygrpc.shutdown_grpc_aio
  File "src/python/grpcio/grpc/_cython/_cygrpc/aio/grpc_aio.pyx.pxi", line 78, in grpc._cython.cygrpc._actual_aio_shutdown
AttributeError: 'NoneType' object has no attribute 'POLLER'
Populated 12 models from file sampled_models_gpt2_629.14K_1.61G_12.json
Benchmarking 11: gpt2-large, gpt2, text-generation, 810.68 M with enable_deepspeed=False
[2022-08-26 00:59:41,283] [INFO] [deployment.py:108:deploy] *************DeepSpeed Optimizations: False*************
[2022-08-26 00:59:41,286] [INFO] [server_client.py:203:_initialize_service] multi-gpu deepspeed launch: ['deepspeed', '--num_nodes', '1', '--num_gpus', '1', '--no_local_rank', '--no_python', '/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'gpt2-large', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/gpt2-large', '--port', '50050', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==']
Warning: Permanently added '[192.168.0.67]:48852' (ECDSA) to the list of known hosts.
[2022-08-26 00:59:43,497] [INFO] [runner.py:415:main] Using IP address of 192.168.0.67 for node worker-0
[2022-08-26 00:59:43,498] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=192.168.0.67 --master_port=29500 --no_python --no_local_rank /opt/conda/bin/python -m mii.launch.multi_gpu_server --task-name text-generation --model gpt2-large --model-path /home/amawa/DeepSpeed-MII/benchmarks/.cache/models/gpt2-large --port 50050 --provider hugging-face --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ==
[2022-08-26 00:59:45,142] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-08-26 00:59:45,142] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-08-26 00:59:45,142] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-08-26 00:59:45,142] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-08-26 00:59:45,142] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-08-26 00:59:45,142] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-08-26 00:59:45,142] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-08-26 00:59:45,142] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-08-26 00:59:45,142] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-08-26 00:59:45,142] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-08-26 00:59:45,142] [INFO] [launch.py:156:main] dist_world_size=1
[2022-08-26 00:59:45,142] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0
[2022-08-26 00:59:46,302] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
2022-08-26 00:59:47.374740: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[2022-08-26 00:59:51,307] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 00:59:56,310] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
[2022-08-26 01:00:01,314] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
E0826 01:00:01.926435436   43258 chttp2_server.cc:1080]      {"created":"@1661457601.926374462","description":"No address added out of total 1 resolved for '[::]:50050'","file":"src/core/ext/transport/chttp2/server/chttp2_server.cc","file_line":976,"referenced_errors":[{"created":"@1661457601.926362910","description":"Failed to add any wildcard listeners","file":"src/core/lib/iomgr/tcp_server_posix.cc","file_line":363,"referenced_errors":[{"created":"@1661457601.926353502","description":"Unable to configure socket","fd":25,"file":"src/core/lib/iomgr/tcp_server_utils_posix_common.cc","file_line":220,"referenced_errors":[{"created":"@1661457601.926351148","description":"Address already in use","errno":98,"file":"src/core/lib/iomgr/tcp_server_utils_posix_common.cc","file_line":194,"os_error":"Address already in use","syscall":"bind"}]},{"created":"@1661457601.926362369","description":"Unable to configure socket","fd":25,"file":"src/core/lib/iomgr/tcp_server_utils_posix_common.cc","file_line":220,"referenced_errors":[{"created":"@1661457601.926360866","description":"Address already in use","errno":98,"file":"src/core/lib/iomgr/tcp_server_utils_posix_common.cc","file_line":194,"os_error":"Address already in use","syscall":"bind"}]}]}]}
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/conda/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/opt/conda/lib/python3.8/site-packages/mii/launch/multi_gpu_server.py", line 70, in <module>
    main()
  File "/opt/conda/lib/python3.8/site-packages/mii/launch/multi_gpu_server.py", line 65, in main
    serve(inference_pipeline, port)
  File "/opt/conda/lib/python3.8/site-packages/mii/grpc_related/modelresponse_server.py", line 95, in serve
    server.add_insecure_port(f'[::]:{port}')
  File "/home/amawa/.local/lib/python3.8/site-packages/grpc/_server.py", line 969, in add_insecure_port
    return _common.validate_port_binding_result(
  File "/home/amawa/.local/lib/python3.8/site-packages/grpc/_common.py", line 166, in validate_port_binding_result
    raise RuntimeError(_ERROR_MESSAGE_PORT_BINDING_FAILED % address)
RuntimeError: Failed to bind to address [::]:50050; set GRPC_VERBOSITY=debug environment variable to see detailed error message.
[2022-08-26 01:00:03,173] [INFO] [launch.py:286:sigkill_handler] Killing subprocess 43258
[2022-08-26 01:00:03,173] [ERROR] [launch.py:292:sigkill_handler] ['/opt/conda/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-generation', '--model', 'gpt2-large', '--model-path', '/home/amawa/DeepSpeed-MII/benchmarks/.cache/models/gpt2-large', '--port', '50050', '--provider', 'hugging-face', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogImZwMTYiLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiB0cnVlfQ=='] exits with return code = 1
[2022-08-26 01:00:06,319] [INFO] [server_client.py:116:_wait_until_server_is_live] waiting for server to start...
Traceback (most recent call last):
  File "bench_models.py", line 154, in <module>
    _deploy_model(model,
  File "bench_models.py", line 43, in _deploy_model
    mii.deploy(task,
  File "/opt/conda/lib/python3.8/site-packages/mii/deployment.py", line 119, in deploy
    return _deploy_local(deployment_name, local_model_path=local_model_path)
  File "/opt/conda/lib/python3.8/site-packages/mii/deployment.py", line 124, in _deploy_local
    mii.import_score_file(deployment_name).init()
  File "/tmp/mii_cache/gpt2-large_deployment/score.py", line 25, in init
    model = mii.MIIServerClient(task,
  File "/opt/conda/lib/python3.8/site-packages/mii/server_client.py", line 91, in __init__
    self._wait_until_server_is_live()
  File "/opt/conda/lib/python3.8/site-packages/mii/server_client.py", line 114, in _wait_until_server_is_live
    raise RuntimeError("server crashed for some reason, unable to proceed")
RuntimeError: server crashed for some reason, unable to proceed
